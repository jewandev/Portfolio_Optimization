# 0.9
set.seed(12)
MA_1_1 <- arima.sim(list(order = c(0,0,1), ma = 0.9), n = 300)
Arima(MA_1_1, order=c(0,0,1))
ggtsdisplay(MA_1_1)
# 0.6
set.seed(12)
MA_1_2 <- arima.sim(list(order = c(0,0,1), ma = 0.6), n = 300)
Arima(MA_1_2, order=c(0,0,1))
ggtsdisplay(MA_1_2)
# -0.8
set.seed(12)
MA_1_3 <- arima.sim(list(order = c(0,0,1), ma = -0.8), n = 300)
Arima(MA_1_3, order=c(0,0,1))
ggtsdisplay(MA_1_3)
# -0.5
set.seed(12)
MA_1_4 <- arima.sim(list(order = c(0,0,1), ma = -0.5), n = 300)
Arima(MA_1_4, order=c(0,0,1))
ggtsdisplay(MA_1_4)
## MA(2) 모형 시뮬레이션
set.seed(12)
MA_2 <- arima.sim(list(order = c(0,0,2), ma = c(0.8, 0.3)), n = 300)
Arima(MA_2, order=c(0,0,2))
ggtsdisplay(MA_2)
autolayer(test)
test
# 가상의 MA 시계열로 분석해보기(Box_Jenkins)
set.seed(12)
MA_1 <- arima.sim(list(order = c(0,0,1), ma = 0.6), n = 300)
train <- window(MA_1, start=1, end=250)
test <- window(MA_1, start=251, end=300)
library(urca)
summary(ur.kpss(train))
Arima(train, order=c(0,0,1))
#auto.arima(train)
MA_1_fit <- Arima(train, order=c(0,0,1))
checkresiduals(MA_1_fit)
Box.test(MA_1_fit$residuals, lag=10, type="Ljung-Box")
MA_1_F <- forecast(MA_1_fit, h=50)
accuracy(MA_1_F, test)
accuracy(naive(train, h=50), test)
accuracy(meanf(train, h=50), test)
autoplot(a_1_F)+
autolayer(fitted(a_1_F),series="fitted")+
autolayer(test)
autoplot(MA_1_F)+
autolayer(fitted(a_1_F),series="fitted")+
autolayer(test)
autoplot(MA_1_F)+
autolayer(fitted(MA_1_F),series="fitted")+
autolayer(test)
autoplot(MA_1_F)+
autolayer(fitted(MA_1_F),series="fitted")+
autolayer(test) +
xlab("Time") + ylab("AR(1) simulation")
autoplot(MA_1_F)+
autolayer(fitted(MA_1_F),series="fitted")+
autolayer(test) +
xlab("Time") + ylab("AR(1) simulation")
autoplot(MA_1_F)+
autolayer(fitted(MA_1_F),series="fitted")+
autolayer(test)
xlab("Time") + ylab("AR(1) simulation")
autoplot(MA_1_F)+
autolayer(fitted(MA_1_F),series="fitted")+
xlab("Time") + ylab("AR(1) simulation")
autoplot(MA_1_F)+
autolayer(fitted(MA_1_F),series="fitted")+
xlab("Time") + ylab("MA(1) simulation")
MA_1_F
autoplot(MA_1_F)+
autolayer(fitted(MA_1_F),series="fitted")+
xlab("Time") + ylab("MA(1) simulation")
# 5/25----
set.seed(1234)
arma_1_1 <- arima.sim(model = list(order=c(1,0,1), ar=0.7, ma=-0.2), n = 200)
ggtsdisplay(arma_1_1)
# 5/25----
library(forecast)
library(urca)
ggtsdisplay(arma_1_1)
Arima(arma_1_1, order=c(1, 0, 1))
auto.arima(arma_1_1)
arma_1_1
auto.arima(arma_1_1)
Arima(arma_1_1, order=c(1, 0, 1))
auto.arima(arma_1_1)
# 파이 >0 세타1 > 0
set.seed(1234)
arma_1_1 <- arima.sim(model = list(order=c(1,0,1), ar=0.7, ma=0.2), n = 200)
ggtsdisplay(arma_1_1)
Arima(arma_1_1, order=c(1, 0, 1))
auto.arima(arma_1_1)
# 파이 < 0, 세타1 < 0
set.seed(1234)
arma_1_1 <- arima.sim(model = list(order=c(1,0,1), ar=-0.7, ma=-0.2), n = 200)
ggtsdisplay(arma_1_1)
Arima(arma_1_1, order=c(1, 0, 1))
auto.arima(arma_1_1)
# 파이 < 0, 세타1 > 0
set.seed(1234)
arma_1_1 <- arima.sim(model = list(order=c(1,0,1), ar=-0.7, ma=0.2), n = 200)
ggtsdisplay(arma_1_1)
ggtsdisplay(arma_1_1)
Arima(arma_1_1, order=c(1, 0, 1))
auto.arima(arma_1_1)
## ARMA(2,2)
set.seed(1234)
arma_2_1 <- arima.sim(model = list(order=c(2,0,1), ar=c(0.7,-0.6), ma=0.4), n = 300)
ggtsdisplay(arma_2_1)
Arima(arma_2_1, order=c(2, 0, 1))
auto.arima(arma_2_1)
# 6/8
library(forecast)
library(urca)
library(fpp2)
autoplot(euretail) + ylab("Retail Index") + xlab("year")
library(fpp2)
library(forecast)
library(urca)
data <- sheep
ggtsdisplay(data)
summury(ur.kpss(data))
summary(ur.kpss(data))
# 데이터의 추세가 보이고
# 검정통계량(1.33)이 1% 유의수준 임계값(0.739)보다 크므로 귀무가설 기각
# 따라서 비정상 시계열이므로 차분 진행
ggtsdisplay(diff(data))
summary(ur.kpss(diff(data)))
m1 <- Arima(data, orber = c(1, 1, 2))
m1 <- Arima(data, orber = c(1, 1, 3))
# 판별
#차분한 데이터의 ACF는 1~3개, PACF는 2~3개가 튀고 있으므로 AR(1~3), MA(2~3)으로 추정
m1 <- Arima(data, order=c(3,1,3))
m1 <- Arima(data, orber=c(1,1,2))
m1 <- Arima(data, orber = c(3, 1, 3))
m1 <- Arima(data, orber = c(3, 1, 3))
# 판별
#차분한 데이터의 ACF는 1~3개, PACF는 2~3개가 튀고 있으므로 AR(1~3), MA(2~3)으로 추정
m1 <- Arima(data, order=c(3,1,3))
m1 <- Arima(data, order = c(3, 1, 3))
m1 <- Arima(data, order = c(1, 1, 2))
m1 <- Arima(data, orber=c(1,1,2))
# 판별
#차분한 데이터의 ACF는 1~3개, PACF는 2~3개가 튀고 있으므로 AR(1~3), MA(2~3)으로 추정
m1 <- Arima(data, order=c(1,1,2))
# 판별
#차분한 데이터의 ACF는 1~3개, PACF는 2~3개가 튀고 있으므로 AR(1~3), MA(2~3)으로 추정
m1 <- Arima(data, order=c(1,1,2))
m2 <- Arima(data, order=c(1,1,3))
m3 <- Arima(data, order=c(2,1,2))
m4 <- Arima(data, order=c(2,1,3))
m5 <- Arima(data, order=c(3,1,2))
m6 <- Arima(data, order=c(3,1,3))
m1
m1
m2 # AICc = 834.8
m3 # AICc = 834.8
m4 # AICc = 834.8
m5 # AICc = 834.8
m6 # AICc = 834.8
# RMSE 값
summary(m1)
summary(m2) #
summary(m3)
summary(m4)
summary(m5)
summary(m6)
# 판별
auto.arima(data)
#차분한 데이터의 PACF는 1~3개(AR(1~3)), ACF는 2~3개(MA(2~3))가 튀고 있고, auto.arima() 값은 Arima(3,1,0)으로 추정했다.
m1 <- Arima(data, order=c(3,1,0)) # 추정
m2 <- Arima(data, order=c(3,1,2))
m3 <- Arima(data, order=c(3,1,3))
m4 <- Arima(data, order=c(2,1,2))
m5 <- Arima(data, order=c(2,1,3))
m6 <- Arima(data, order=c(1,1,2))
# AICc 값
m1 # AICc=834.8
m2 # AICc=830.04
m3 # AICc=825.18
m4 # AICc=827.27
m5 # AICc=827.41
m6 # AICc=828.63
# RMSE 값
summary(m1) # 74.42045
summary(m2) # 70.69763
summary(m3) # 68.2395
summary(m4) # 68.10174
summary(m5) # 68.16674
summary(m6) # 66.99864
# 진단
checkresiduals(m1)
checkresiduals(m2)
checkresiduals(m3)
checkresiduals(m4)
checkresiduals(m5)
checkresiduals(m6)
# 예측
m3
# 예측
fit <- forecast(m3, h=10)
fit
fit$mean
fit$forecast
fit$mean
#그래프
autoplot(data) +
autolayer(fit$fitted, series = 'fitted') +
autolayer(fit, series = 'pred')
# 추정식
m3
###2번
# 예비분석
data <- ibmclose
train <- window(data, start = 1, end = 349)
test <- window(data, start = 350)
ggtsdisplay(train)
# ACF는 모든 Lag에서 신뢰구간을 넘으며 선형으로 감소하고, PACF에서는 Lag1만 신뢰구간을 넘은 것으로 보아
# 랜던뭐크의 그래프임을 알 수 있다.
summary(ur.kpss(train))
ggtsdisplay(diff(train))
summary(ur.kpss(diff(train)))
ggtsdisplay(train)
ggtsdisplay(diff(train))
# 판별
# 원데이터는 전형적인 Arima(0,1,0)의 모양을 보이고 있으므로 Arima(0,1,0)로 추정.
auto.arima(data)
# 판별
# 원데이터는 전형적인 Arima(0,1,0)의 모양을 보이고 있으므로 Arima(0,1,0)로 추정한다.
# 대안으로는 AR(1),MA(1), ARMA(1,1)
m1 <- Arima(train, order=c(0,1,0)) # 추정
m2 <- Arima(train, order=c(1,1,0))
m3 <- Arima(train, order=c(0,1,1))
m4 <- Arima(train, order=c(1,1,1))
# 추정
m1
m2
m3 #
m4 #
m2 # AICc=2365.06
# 진단
checkresiduals(m1)
# 진단
checkresiduals(m1)
checkresiduals(m2)
checkresiduals(m3)
checkresiduals(m4)
# RMSE
summary(m1)
summary(m2)
summary(m3)
summary(m4)
summary(m2) # 7.184309
# 예측값
fit <- forecast(m2, h=20)
fit$mean
# 그래프
autoplot(train) +
autolayer(fit$fitted, series = 'fitted') +
autolayer(fit, series = 'pred')
# 예측
fit <- forecast(m4, h=20)
fit$mean # 예측값
# 그래프
autoplot(train) +
autolayer(fit$fitted, series = 'fitted') +
autolayer(fit, series = 'pred')
fit$mean # 예측값
# 예측
fit <- forecast(m2, h=20)
fit$mean # 예측값
# 그래프
autoplot(train) +
autolayer(fit$fitted, series = 'fitted') +
autolayer(fit, series = 'pred')
fit
fit$mean # 예측값
# 예측
h = 20
fit <- forecast(m2, h=h)
fit$mean # 예측값
# 그래프
autoplot(train) +
autolayer(fit$fitted, series = 'fitted') +
autolayer(fit, series = 'pred')
STL <- stlf(train, lambda=0, h=h)
stlf
# 앙상블 모형
ETS <- forecast(ets(train), h = h)
ARIMA <- fit
STL <- stlf(train, lambda=0, h=h)
NNAR <- forecast(nnetar(train), h=h)
combination <- ETS[["mean"]] + ARIMA[["mean"]]+NNAR[["mean"]]/3
c(ETS = accuracy(ETS,test)["Test set", "RMSE"],
ARIMA = accuracy(ARIMA, test)["Test set", "RMSE"],
NNAR = accuracy(NNAR, test)["Test set", "RMSE"],
combination = accuracy(combination, test)["Test set", "RMSE"])
combination <- (ETS[["mean"]] + ARIMA[["mean"]]+NNAR[["mean"]])/3
c(ETS = accuracy(ETS,test)["Test set", "RMSE"],
ARIMA = accuracy(ARIMA, test)["Test set", "RMSE"],
NNAR = accuracy(NNAR, test)["Test set", "RMSE"],
combination = accuracy(combination, test)["Test set", "RMSE"])
accuracy(fit, test)
accuracy(fit,test)["Test set", "RMSE"]
# tsCV
far2 <- function(train, h){fit}
# tsCV
#fit_far <- function(x, h){forecast(x, order=c(1,1,0)),h=h}
e <- tsCV(train, fit, h=h, window = 30)
e
# tsCV
far2 <- function(x, h){forecast(x, order=c(2,0,0)),h=h}
# tsCV
far2 <- function(x, h){forecast(x, order=c(2,0,0)),h=h}
# tsCV
far2 <- function(x, h){forecast(Arima(x, order=c(2,0,0)),h=h)}
e <- tsCV(train, far2, h=h, window = 30)
e
# tsCV
far2 <- function(x, h){forecast(Arima(x, order=c(1,1,0)),h=h)}
e <- tsCV(train, far2, h=h, window = 30)
e
summary(m2) # 7.184309
# tsCV
far2 <- function(x, h){forecast(Arima(x, order=c(1,1,0)),h=h)}
e <- tsCV(train, far2, h=h, window = 30)
e
autoplot(e)
autoplot(e[30])
autoplot(e[31])
autoplot(e)
autoplot(e[31])
e[30]
e[31]
e
fit[1]
fit$mean[1]
fit$mean[1];e[31]
test[1] - autoplot(e[31])
test[1]
fit1 <- forecast(m1, h=h)
fit2 <- forecast(m2, h=h)
fit3 <- forecast(m3, h=h)
fit4 <- forecast(m4, h=h)
combination <- (fit1[["mean"]]+fit2[["mean"]]+fit3[["mean"]]+fit4[["mean"]]))/4
combination <- (fit1[["mean"]]+fit2[["mean"]]+fit3[["mean"]]+fit4[["mean"]])/4
c(m1 = accuracy(fit1, test)["Test set", "RMSE"],
m2 = accuracy(fit2, test)["Test set", "RMSE"],
m3 = accuracy(fit3, test)["Test set", "RMSE"],
m4 = accuracy(fit4, test)["Test set", "RMSE"],
combination = accuracy(combination, test)["Test set", "RMSE"])
# 앙상블 모형
ETS <- forecast(ets(train), h = h)
ARIMA <- fit
#STL <- stlf(train, lambda=0, h=h)
NNAR <- forecast(nnetar(train), h=h)
combination <- (ETS[["mean"]] + ARIMA[["mean"]]+NNAR[["mean"]])/3
c(ETS = accuracy(ETS,test)["Test set", "RMSE"],
ARIMA = accuracy(ARIMA, test)["Test set", "RMSE"],
NNAR = accuracy(NNAR, test)["Test set", "RMSE"],
combination = accuracy(combination, test)["Test set", "RMSE"])
library(fpp2)
library(forecast)
library(urca)
# 1.1
data <- sheep
ggtsdisplay(data)
summary(ur.kpss(data))
ggtsdisplay(diff(data))
summary(ur.kpss(diff(data)))
# 1.2
auto.arima(data)
#차분한 데이터의 PACF는 1~3개(AR(1~3)), ACF는 2~3개(MA(2~3))가 튀고 있고, auto.arima() 값은 Arima(3,1,0)으로 추정했다.
m1 <- Arima(data, order=c(3,1,0)) # 추정
# AR(1~3), MA(2~3)이 대안
m2 <- Arima(data, order=c(3,1,2))
m3 <- Arima(data, order=c(3,1,3))
m4 <- Arima(data, order=c(2,1,2))
m5 <- Arima(data, order=c(2,1,3))
m6 <- Arima(data, order=c(1,1,2))
# 1.3
# AICc 값
m1 # AICc=823.71
m2 # AICc=827.41
m3 # AICc=828.63
m4 # AICc=825.18
m5 # AICc=827.27
m6 # AICc=834.8
# 1.4
# 진단 1.4
# 잔차
checkresiduals(m1)
checkresiduals(m2)
checkresiduals(m3)
checkresiduals(m4)
checkresiduals(m5)
checkresiduals(m6)
# RMSE 값
summary(m1) # 68.68715
summary(m2) # 68.16674
summary(m3) # 66.99864
summary(m4) # 68.2395
summary(m5) # 68.10174
summary(m6) # 74.42045
# 1.5
h = 10
fit <- forecast(m3, h=h)
model <- m3
fit <- forecast(model, h=h)
fit$mean # 예측값
#그래프
autoplot(data) +
autolayer(fit$fitted, series = 'fitted') +
autolayer(fit, series = 'pred')
fit$mean # 예측값
# 1.6
m3
# 1.6
model
# 2.1
data <- ibmclose
train <- window(data, start = 1, end = 349)
test <- window(data, start = 350)
ggtsdisplay(train)
summary(ur.kpss(train))
ggtsdisplay(diff(train))
summary(ur.kpss(diff(train)))
# 2.3
# AICc
m1 # AICc=2367.04
# 2.2
m1 <- Arima(train, order=c(0,1,0)) # 추정
m2 <- Arima(train, order=c(1,1,0))
m3 <- Arima(train, order=c(0,1,1))
m4 <- Arima(train, order=c(1,1,1))
# 2.3
# AICc
m1 # AICc=2367.04
m2 # AICc=2365.06
m3 # AICc=2365.12
m4 # AICc=2367.09
# 2.4
# 잔차
checkresiduals(m1)
checkresiduals(m2)
checkresiduals(m3)
checkresiduals(m4)
# RMSE
summary(m1) # 7.225831
summary(m2) # 7.184309
summary(m3) # 7.184884
summary(m4) # 7.184244
# 2.5
h = 20
# 2.5
h = 20
model <- m2
fit <- forecast(model, h=h)
fit$mean # 예측값
# 그래프
autoplot(train) +
autolayer(fit$fitted, series = 'fitted') +
autolayer(fit, series = 'pred')
# 2.5
h = 20
model <- m2
fit <- forecast(model, h=h)
# 그래프
autoplot(train) +
autolayer(fit$fitted, series = 'fitted') +
autolayer(fit, series = 'pred')
fit$mean # 예측값
STL <- stlf(train, lambda=0, h=h)
# 2.6
ETS <- forecast(ets(train), h = h)
ARIMA <- fit
NNAR <- forecast(nnetar(train), h=h)
combination <- (ETS[["mean"]] + ARIMA[["mean"]]+NNAR[["mean"]])/3
c(ETS = accuracy(ETS,test)["Test set", "RMSE"],
ARIMA = accuracy(ARIMA, test)["Test set", "RMSE"],
NNAR = accuracy(NNAR, test)["Test set", "RMSE"],
combination = accuracy(combination, test)["Test set", "RMSE"])
c(ETS = accuracy(ETS,test)["Test set", "RMSE"],
ARIMA = accuracy(ARIMA, test)["Test set", "RMSE"],
NNAR = accuracy(NNAR, test)["Test set", "RMSE"],
combination = accuracy(combination, test)["Test set", "RMSE"])
fit1 <- forecast(m1, h=h)
fit2 <- forecast(m2, h=h)
fit3 <- forecast(m3, h=h)
fit4 <- forecast(m4, h=h)
combination2 <- (fit1[["mean"]]+fit2[["mean"]]+fit3[["mean"]]+fit4[["mean"]])/4
c(m1 = accuracy(fit1, test)["Test set", "RMSE"],
m2 = accuracy(fit2, test)["Test set", "RMSE"],
m3 = accuracy(fit3, test)["Test set", "RMSE"],
m4 = accuracy(fit4, test)["Test set", "RMSE"],
combination2 = accuracy(combination2, test)["Test set", "RMSE"])
# kospi, kosdaq, usd_krw 종가만 추출 ----
getwd()
setwd('/Users/wan/GitHub/Portfolio_Optimization/time_series_clustering/')
### 코스피
kospi <- read.csv('data/kospi.csv')
library(dplyr)
glimpse(kospi)
library(timetk)
kospi_price <- kospi[c(1, 2)]
colnames(kospi_price) <- (c('Date', 'Price'))
kospi_price <- na.omit(kospi_price)
library(readr)
kospi_price$Price <- parse_number(kospi_price$Price) # 열에서 숫자만 추출
kospi_price$Date <- ymd(kospi_price$Date) # ymd()로 형태를 yyyy-mm-dd로 변경
